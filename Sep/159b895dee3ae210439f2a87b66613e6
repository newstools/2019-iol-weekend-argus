In a recent panel discussion, experts agreed that the government needed to adopt guidelines like the ones established by the EU, which outlines trustworthy AI. The EU position on AI is it should be used lawfully, ethically and in a robust manner. According to the guidelines, the seven key requirements for trustworthy AI are: human agency and empowerment, technical robustness and safety, privacy and data governance, transparency, fairness, societal and environmental well-being, and accountability. Dr Jacques Ludik, Cortex founder, said we were living in a smart technology era where data was generated at an exponential rate. This data can either be used for the collective good to inform and protect, or it can be abused and used for manipulation. Ludik said: “How our data is used, and the associated violations of privacy were highlighted last year during the scandal surrounding Facebook and Cambridge Analytica which saw Cambridge Analytica harvesting the personal data of millions of people’s Facebook profiles, without consent, and used for political advertising.” But Professor Jacques Snyman, chief executive of Icon Oncology, said sharing data could be used for good - collective data was offering real-life evidence to understand what medication works best for patients outside of medical studies. Dr Nick Bradshaw, co-founder of AI Media Africa, said more incidents like Cambridge Analytica one would happen. “Companies with ethics and privacy at their core will pioneer in this and those companies that don’t will die,” Bradshaw said. Weekend Argus